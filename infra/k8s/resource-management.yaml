apiVersion: v1
kind: LimitRange
metadata:
  name: todo-app-limits
  namespace: todo-app
  labels:
    app.kubernetes.io/name: todo-app
    app.kubernetes.io/component: resource-management
spec:
  limits:
  # Container limits
  - type: Container
    default:
      cpu: "500m"
      memory: "512Mi"
    defaultRequest:
      cpu: "100m"
      memory: "128Mi"
    max:
      cpu: "2"
      memory: "2Gi"
    min:
      cpu: "50m"
      memory: "64Mi"
  # Pod limits
  - type: Pod
    max:
      cpu: "4"
      memory: "4Gi"
    min:
      cpu: "100m"
      memory: "128Mi"
  # PVC limits
  - type: PersistentVolumeClaim
    max:
      storage: "100Gi"
    min:
      storage: "1Gi"
---
apiVersion: v1
kind: ResourceQuota
metadata:
  name: todo-app-quota
  namespace: todo-app
  labels:
    app.kubernetes.io/name: todo-app
    app.kubernetes.io/component: resource-management
spec:
  hard:
    # Compute resources
    requests.cpu: "4"
    requests.memory: "8Gi"
    limits.cpu: "8"
    limits.memory: "16Gi"
    
    # Storage resources
    requests.storage: "100Gi"
    persistentvolumeclaims: "10"
    
    # Object counts
    pods: "20"
    services: "10"
    secrets: "10"
    configmaps: "10"
    replicationcontrollers: "0"
    
    # Load balancers
    services.loadbalancers: "2"
    services.nodeports: "5"
---
# Priority Classes for workload prioritization
apiVersion: scheduling.k8s.io/v1
kind: PriorityClass
metadata:
  name: todo-app-high-priority
  labels:
    app.kubernetes.io/name: todo-app
    app.kubernetes.io/component: resource-management
value: 1000
globalDefault: false
description: "High priority class for critical Todo App components"
---
apiVersion: scheduling.k8s.io/v1
kind: PriorityClass
metadata:
  name: todo-app-medium-priority
  labels:
    app.kubernetes.io/name: todo-app
    app.kubernetes.io/component: resource-management
value: 500
globalDefault: false
description: "Medium priority class for Todo App components"
---
apiVersion: scheduling.k8s.io/v1
kind: PriorityClass
metadata:
  name: todo-app-low-priority
  labels:
    app.kubernetes.io/name: todo-app
    app.kubernetes.io/component: resource-management
value: 100
globalDefault: false
description: "Low priority class for non-critical Todo App components"
---
# Pod Disruption Budget for API
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: todo-api-pdb
  namespace: todo-app
  labels:
    app.kubernetes.io/name: todo-app
    app.kubernetes.io/component: api
spec:
  minAvailable: 2
  selector:
    matchLabels:
      app.kubernetes.io/name: todo-app
      app.kubernetes.io/component: api
---
# Pod Disruption Budget for Web
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: todo-web-pdb
  namespace: todo-app
  labels:
    app.kubernetes.io/name: todo-app
    app.kubernetes.io/component: web
spec:
  minAvailable: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: todo-app
      app.kubernetes.io/component: web
---
# Pod Disruption Budget for NGINX
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: nginx-pdb
  namespace: todo-app
  labels:
    app.kubernetes.io/name: todo-app
    app.kubernetes.io/component: nginx
spec:
  minAvailable: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: todo-app
      app.kubernetes.io/component: nginx
---
# Vertical Pod Autoscaler for API (if VPA is installed)
apiVersion: autoscaling.k8s.io/v1
kind: VerticalPodAutoscaler
metadata:
  name: todo-api-vpa
  namespace: todo-app
  labels:
    app.kubernetes.io/name: todo-app
    app.kubernetes.io/component: api
spec:
  targetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: todo-api
  updatePolicy:
    updateMode: "Auto"
  resourcePolicy:
    containerPolicies:
    - containerName: api
      maxAllowed:
        cpu: "1"
        memory: "1Gi"
      minAllowed:
        cpu: "100m"
        memory: "128Mi"
      controlledResources: ["cpu", "memory"]
---
# Network Policy for database access
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: database-access-policy
  namespace: todo-app
  labels:
    app.kubernetes.io/name: todo-app
    app.kubernetes.io/component: network-policy
spec:
  podSelector:
    matchLabels:
      app.kubernetes.io/component: mongodb
  policyTypes:
  - Ingress
  ingress:
  - from:
    - podSelector:
        matchLabels:
          app.kubernetes.io/component: api
    - podSelector:
        matchLabels:
          app.kubernetes.io/component: ingestion
    ports:
    - protocol: TCP
      port: 27017
---
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: redis-access-policy
  namespace: todo-app
  labels:
    app.kubernetes.io/name: todo-app
    app.kubernetes.io/component: network-policy
spec:
  podSelector:
    matchLabels:
      app.kubernetes.io/component: redis
  policyTypes:
  - Ingress
  ingress:
  - from:
    - podSelector:
        matchLabels:
          app.kubernetes.io/component: api
    - podSelector:
        matchLabels:
          app.kubernetes.io/component: ingestion
    ports:
    - protocol: TCP
      port: 6379
---
# Service Monitor for Prometheus (if Prometheus Operator is used)
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: todo-app-metrics
  namespace: todo-app
  labels:
    app.kubernetes.io/name: todo-app
    app.kubernetes.io/component: monitoring
spec:
  selector:
    matchLabels:
      app.kubernetes.io/name: todo-app
  endpoints:
  - port: http
    path: /metrics
    interval: 30s
    scrapeTimeout: 10s
  - port: metrics
    path: /metrics
    interval: 30s
    scrapeTimeout: 10s
---
# Pod Security Standards (Pod Security Policy replacement)
apiVersion: v1
kind: Namespace
metadata:
  name: todo-app
  labels:
    name: todo-app
    pod-security.kubernetes.io/enforce: restricted
    pod-security.kubernetes.io/audit: restricted
    pod-security.kubernetes.io/warn: restricted
---
# Cluster Autoscaler annotations for node scaling
apiVersion: v1
kind: ConfigMap
metadata:
  name: cluster-autoscaler-status
  namespace: kube-system
  labels:
    app.kubernetes.io/name: todo-app
    app.kubernetes.io/component: autoscaling
data:
  nodes.max: "10"
  nodes.min: "3"
  scale-down-delay-after-add: "10m"
  scale-down-unneeded-time: "10m"